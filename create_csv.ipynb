{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import csv\n",
    "import requests\n",
    "from datetime import datetime as dt, timezone\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONGRESS = 116\n",
    "CONGRESS_DATA_ROOT = f'E:/congress/data/{CONGRESS}'\n",
    "BILL_DATA_ROOT = os.path.join(CONGRESS_DATA_ROOT, 'bills')\n",
    "BT_DATA_ROOT = f'E:/BillTracker/data'\n",
    "BT_CACHE_ROOT = f'E:/BillTracker/cache'\n",
    "BT_LEGISLATORS = f'E:/BillTracker/legislators/legislators-{CONGRESS}.csv'\n",
    "BT_PARTY_CACHE = os.path.join(BT_CACHE_ROOT, f'party-cache-{CONGRESS}.json')\n",
    "BT_BILL_CACHE = os.path.join(BT_CACHE_ROOT, f'bill-cache-{CONGRESS}.json')\n",
    "BT_BILLS = os.path.join(BT_DATA_ROOT, f'bills-{CONGRESS}.csv')\n",
    "BT_SPONSORS =  os.path.join(BT_CACHE_ROOT, f'bill-sponsors-{CONGRESS}.json')\n",
    "\n",
    "KEY = 'Jx3d2IH9lVJ6LByLVnPLOUj120B40l2FLDKYCopw'\n",
    "\n",
    "columns = ['bill_id', 'bill_type', 'party', 'introduced_at', 'status', 'subject', 'sponsor', 'cosponsors', 'status_at', 'lastmod']\n",
    "# bill_types = ['hr', 's', 'hres', 'hconres', 'hjres', 'sconres', 'sjres', 'sres']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = os.path.normpath(BILL_DATA_ROOT)\n",
    "path = os.path.join(path, 'hconres', 'hconres37', 'data.json')\n",
    "path\n",
    "\n",
    "def test(path):\n",
    "    testbill_cache = {}\n",
    "    test = load_bill(path)\n",
    "    \n",
    "  \n",
    "    path = os.path.join(BILL_DATA_ROOT, 'hconres', 'hconres37', 'fdsys_billstatus-lastmod.txt')\n",
    "    set_bill_cache('id', testbill_cache, entry={'lastmod':get_govinfo_lastmod(path)})\n",
    "    #print(testbill_cache)\n",
    "    \n",
    "   \n",
    "    bt_bill_path = os.path.join(BT_DATA_ROOT, f'bills-{CONGRESS}.csv')\n",
    "    bt_data_path = os.path.join(BT_DATA_ROOT, f'bills-{CONGRESS}-s.csv')\n",
    "    data = get_bill_data(bt_bill_path)\n",
    "    print(data)\n",
    "    dump_to_csv(bt_data_path, list(data.values()))\n",
    "        \n",
    "\n",
    "# test(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_legislators(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "legislators = get_legislators(BT_LEGISLATORS)\n",
    "\n",
    "def get_party(id): \n",
    "    try:\n",
    "        return legislators[legislators['bioguide_id'] == id]['party'].item()\n",
    "    except ValueError as e:\n",
    "        party = check_party_cache(id)\n",
    "        return party if party else get_party_req(id) \n",
    "    except Exception as e: \n",
    "        print(\"Unexpected Error: \", e)\n",
    "        return None\n",
    "    \n",
    "# TODO: Create legislator cache  \n",
    "def get_party_req(id):\n",
    "    url = f'https://api.propublica.org/congress/v1/members/{id}.json'\n",
    "    r = requests.get(url, headers={\"X-API-Key\": KEY})\n",
    "    \n",
    "    try:\n",
    "        print(\"Error getting {0}. Trying alternate download.\".format(id))\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        party = data['results'][0]['current_party']\n",
    "        \n",
    "        set_party_entry( id, entry={ 'party': party } )\n",
    "        \n",
    "        return party\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(\"Error getting ProPublica request.\", e)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(\"Unexpected Error: \", e)\n",
    "        return None\n",
    "\n",
    "def get_json_cache(path):\n",
    "    data = {}\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "    \n",
    "    return data\n",
    "\n",
    "party_cache = get_json_cache(BT_PARTY_CACHE)\n",
    "\n",
    "def set_party_entry(id, entry):\n",
    "    party_cache[id] = entry\n",
    "\n",
    "def dump_cache(path, cache):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(cache, f, indent=4)\n",
    "\n",
    "def check_party_cache(id):\n",
    "    if id in party_cache:\n",
    "        return party_cache[id]['party']\n",
    "    \n",
    "    return None\n",
    "\n",
    "def set_cache_entry(id, cache, entry):\n",
    "    cache[id] = entry\n",
    "    \n",
    "    return cache\n",
    "\n",
    "def is_in_cache(id, cache):\n",
    "    if cache and id in cache:\n",
    "        return cache[id]\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bill(path):\n",
    "    data = {}\n",
    "    \n",
    "    try: \n",
    "        with open(path, 'r') as f:\n",
    "            raw_data = json.load(f)\n",
    "            data['bill_id'] = raw_data['bill_id'].split('-')[0]\n",
    "            data['bill_type'] = raw_data['bill_type']\n",
    "            data['party'] = get_party(raw_data['sponsor']['bioguide_id'])\n",
    "            data['introduced_at'] = raw_data['introduced_at']\n",
    "            data['status'] = raw_data['status']\n",
    "            data['subject'] = raw_data['subjects_top_term']\n",
    "            data['sponsor'] = raw_data['sponsor']['name']\n",
    "            data['cosponsors'] = len(raw_data['cosponsors'])\n",
    "            data['status_at'] = raw_data['status_at']\n",
    "            data['lastmod'] = dt.astimezone(dt.now(), tz=timezone.utc).isoformat(timespec='minutes') \n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"Error loading: {0}\", path, e)\n",
    "    finally: \n",
    "        return data\n",
    "\n",
    "def load_sponsor_id(path):\n",
    "    data = {}\n",
    "    \n",
    "    try: \n",
    "        with open(path, 'r') as f:\n",
    "            raw_data = json.load(f)\n",
    "            data['bio_id'] = raw_data['sponsor']['bioguide_id']\n",
    "            data['bill_id'] = raw_data['bill_id'].split('-')[0]\n",
    "            data['party'] = get_party(raw_data['sponsor']['bioguide_id'])\n",
    "            data['introduced_at'] = raw_data['introduced_at']\n",
    "            data['subject'] = raw_data['subjects_top_term']\n",
    "            data['sponsor'] = raw_data['sponsor']['name']\n",
    "            data['cosponsors'] = len(raw_data['cosponsors'])\n",
    "            data['status_at'] = raw_data['status_at']\n",
    "            data['lastmod'] = dt.astimezone(dt.now(), tz=timezone.utc).isoformat(timespec='minutes') \n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"Error loading: {0}\", path, e)\n",
    "    finally: \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bill_csv(path):\n",
    "    with open(path, 'w') as f:\n",
    "        dict_writer = csv.DictWriter(f, delimiter=';', fieldnames=columns)\n",
    "        dict_writer.writeheader()\n",
    "\n",
    "def is_bill_cache(id, lastmod, cache):\n",
    "    if cache and id in cache:\n",
    "        return cache[id]['lastmod']\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_govinfo_lastmod(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return f.read().strip()\n",
    "    \n",
    "    return None\n",
    "\n",
    "def set_bill_cache(id, cache, entry):\n",
    "    cache[id] = entry\n",
    "    return cache\n",
    "\n",
    "def get_bill_data(path):\n",
    "    data = {}\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'r') as f:\n",
    "            r = csv.DictReader(f, delimiter=';')\n",
    "            for row in r:\n",
    "                data[row['bill_id']] = row\n",
    "                \n",
    "        \n",
    "    return data\n",
    "\n",
    "def dump_to_csv(path, data):\n",
    "    with open(path, 'w') as f:\n",
    "        dict_writer = csv.DictWriter(f, delimiter=';', fieldnames=columns)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(data)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing directory: hconres\n",
      "Success.\n",
      "Processing directory: hjres\n",
      "Success.\n",
      "Processing directory: hr\n",
      "Success.\n",
      "Processing directory: hres\n",
      "Success.\n",
      "Processing directory: s\n",
      "Success.\n",
      "Processing directory: sconres\n",
      "Success.\n",
      "Processing directory: sjres\n",
      "Success.\n",
      "Processing directory: sres\n",
      "Success.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Test cache \n",
    "# TODO: Segment cache into seperate bill_type files\n",
    "\n",
    "def write_bills_to_gcp(force=False):\n",
    "    # Get bill cache, { bill_id: lastmod }\n",
    "    bill_cache = get_json_cache(BT_BILL_CACHE) \n",
    "    \n",
    "    #Iterate over bill_type root dir\n",
    "    for root_path in os.scandir(BILL_DATA_ROOT):\n",
    "        bill_root = os.path.basename(root_path)\n",
    "        \n",
    "        # Path to BillTracker data storage for [bill_type]\n",
    "        bt_bill_path = os.path.join(BT_DATA_ROOT, f'bills-{CONGRESS}-{bill_root}.csv')\n",
    "        \n",
    "        # Get bill data if it exists, otherwise create new csv \n",
    "        bill_data = get_bill_data(bt_bill_path)\n",
    "        print(\"Processing directory: {0}\".format(bill_root))\n",
    "        \n",
    "        #\n",
    "        for bill_path in os.scandir(os.path.join(BILL_DATA_ROOT, root_path)): \n",
    "\n",
    "            data_path = os.path.join(bill_path, 'data.json')\n",
    "            lastmod_path = os.path.join(bill_path, 'fdsys_billstatus-lastmod.txt')\n",
    "\n",
    "            if os.path.exists(data_path) and os.path.exists(lastmod_path):\n",
    "\n",
    "                lastmod = get_govinfo_lastmod(lastmod_path)\n",
    "                bill_id = os.path.basename(bill_path)\n",
    "                \n",
    "                # Get cache result\n",
    "                cache_result = is_bill_cache(bill_id, lastmod, bill_cache)\n",
    "                if cache_result and not force:\n",
    "                    # On cache hit check if lastmods match\n",
    "                    if not cache_result == lastmod:\n",
    "                        print(bill_id)\n",
    "                        \n",
    "                        # If they do not match, update the row \n",
    "                        bill_cache = set_bill_cache(bill_id, bill_cache, entry={ 'lastmod': lastmod })\n",
    "                        bill_data[bill_id] = load_bill(data_path) \n",
    "                        \n",
    "                    # If cache match, bill was not updated\n",
    "                    # Do nothing \n",
    "                else:\n",
    "                    print(bill_id)\n",
    "                    # Update bill cache \n",
    "                    bill_cache = set_bill_cache(bill_id, bill_cache, entry={ 'lastmod': lastmod })\n",
    "                    bill_data[bill_id] = load_bill(data_path) \n",
    "                    \n",
    "        \n",
    "        dump_to_csv(bt_bill_path, list(bill_data.values()))\n",
    "            \n",
    "        print(\"Success.\")\n",
    "        \n",
    "    dump_cache(BT_PARTY_CACHE, party_cache)\n",
    "    dump_cache(BT_BILL_CACHE, bill_cache)\n",
    " \n",
    "    \n",
    "write_bills_to_gcp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing directory: hconres\n",
      "Processing directory: hjres\n",
      "Processing directory: hr\n",
      "Processing directory: hres\n",
      "Processing directory: s\n",
      "Processing directory: sconres\n",
      "Processing directory: sjres\n",
      "Processing directory: sres\n"
     ]
    }
   ],
   "source": [
    "def write_bill_sponsors():\n",
    "    sponsor_cache = get_json_cache(BT_SPONSORS)\n",
    "    \n",
    "     #Iterate over bill_type root dir\n",
    "    for root_path in os.scandir(BILL_DATA_ROOT):\n",
    "        bill_root = os.path.basename(root_path)\n",
    "        \n",
    "        \n",
    "        print(\"Processing directory: {0}\".format(bill_root))\n",
    "        \n",
    "        #\n",
    "        for bill_path in os.scandir(os.path.join(BILL_DATA_ROOT, root_path)): \n",
    "            data_path = os.path.join(bill_path, 'data.json')\n",
    "            \n",
    "            if os.path.exists(data_path):\n",
    "                sponsor = load_sponsor_id(data_path)\n",
    "                \n",
    "                id = sponsor['bio_id']\n",
    "                if id and not is_in_cache(id, sponsor_cache):\n",
    "                    print(\"F\")\n",
    "                    sponsor_cache = set_cache_entry(id, sponsor_cache, sponsor)\n",
    "        \n",
    "    \n",
    "    dump_cache(BT_SPONSORS, sponsor_cache)\n",
    "                        \n",
    "write_bill_sponsors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
